{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: brainome in /home/azureorbit/.local/lib/python3.8/site-packages (1.8.120)\n",
      "Collecting numpy>=1.20.0\n",
      "  Using cached numpy-1.22.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "Requirement already satisfied: Jinja2>=3.0.0 in /home/azureorbit/.local/lib/python3.8/site-packages (from brainome) (3.0.2)\n",
      "Requirement already satisfied: packaging in /home/azureorbit/.local/lib/python3.8/site-packages (from brainome) (21.2)\n",
      "Requirement already satisfied: xgboost==1.4.2 in /home/azureorbit/.local/lib/python3.8/site-packages (from brainome) (1.4.2)\n",
      "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from brainome) (1.10.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /home/azureorbit/.local/lib/python3.8/site-packages (from brainome) (2021.10.8)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from brainome) (2.22.0)\n",
      "Requirement already satisfied: scikit-learn<=0.24.2,>=0.22.1 in /home/azureorbit/.local/lib/python3.8/site-packages (from brainome) (0.24.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/azureorbit/.local/lib/python3.8/site-packages (from Jinja2>=3.0.0->brainome) (2.0.1)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging->brainome) (2.4.6)\n",
      "Requirement already satisfied: scipy in /home/azureorbit/.local/lib/python3.8/site-packages (from xgboost==1.4.2->brainome) (1.7.1)\n",
      "Requirement already satisfied: typing-extensions in /home/azureorbit/.local/lib/python3.8/site-packages (from torch>=1.4.0->brainome) (4.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/azureorbit/.local/lib/python3.8/site-packages (from scikit-learn<=0.24.2,>=0.22.1->brainome) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/azureorbit/.local/lib/python3.8/site-packages (from scikit-learn<=0.24.2,>=0.22.1->brainome) (3.1.0)\n",
      "\u001b[31mERROR: tensorflow 2.6.1 has requirement numpy~=1.19.2, but you'll have numpy 1.22.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.6.1 has requirement typing-extensions~=3.7.4, but you'll have typing-extensions 4.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: strym 0.4.15 has requirement numpy~=1.19.2, but you'll have numpy 1.22.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-gpu 2.7.0 has requirement keras<2.8,>=2.7.0rc0, but you'll have keras 2.6.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-gpu 2.7.0 has requirement tensorflow-estimator<2.8,~=2.7.0rc0, but you'll have tensorflow-estimator 2.6.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: stable-baselines3 1.3.0 has requirement gym<0.20,>=0.17, but you'll have gym 0.21.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "Successfully installed numpy-1.22.3\n",
      "\n",
      "\n",
      "Checking brainome version number:\n",
      "brainome v1.8-120-prod\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install brainome\n",
    "print(\"\\n\\nChecking brainome version number:\")\n",
    "!brainome --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/azureorbit/.local/lib/python3.8/site-packages (1.3.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3/dist-packages (from pandas) (2.7.3)\r\n",
      "Requirement already satisfied: numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in /home/azureorbit/.local/lib/python3.8/site-packages (from pandas) (1.22.3)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas) (2019.3)\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: brainome [-h] [-version] [-headerless] [-target TARGET]\r\n",
      "                [-ignorecolumns IGNORECOLUMNS] [-rank [ATTRIBUTERANK]]\r\n",
      "                [-measureonly] [-f FORCEMODEL] [-nosplit] [-split FORCESPLIT]\r\n",
      "                [-nsamples NSAMPLES] [-ignoreclasses IGNORELABELS]\r\n",
      "                [-usecolumns IMPORTANTCOLUMNS] [-o OUTPUT] [-v] [-q] [-y]\r\n",
      "                [-e EFFORT] [-biasmeter] [-novalidation] [-nofun] [-modelonly]\r\n",
      "                [-json JSON] [-C REGULARIZATION_STRENGTH]\r\n",
      "                input [input ...]\r\n",
      "\r\n",
      "\u001b[01;30mBrainome Table Compiler (tm)  v1.8-120-prod\u001b[0m\r\n",
      "\r\n",
      "\u001b[01;1mRequired arguments\u001b[0m:\r\n",
      "  input                 Table as CSV files and/or URLs or Command above\r\n",
      "\r\n",
      "\u001b[01;1mOptional arguments\u001b[0m:\r\n",
      "  -h                    show this help message and exit\r\n",
      "  -version, --version   show program's version number and exit\r\n",
      "\r\n",
      "\u001b[01;1mBasic options\u001b[0m:\r\n",
      "  -headerless           Headerless CSV input file.\r\n",
      "  -target TARGET        Specify target column by name or number. Default: last column of table.\r\n",
      "  -ignorecolumns IGNORECOLUMNS\r\n",
      "                        Comma-separated list of columns to ignore by name or number.\r\n",
      "  -rank [ATTRIBUTERANK]\r\n",
      "                        Select the optimal subset of columns for accuracy on held out data\r\n",
      "                        If optional parameter N is given, select the optimal N columns. Works best for DT.\r\n",
      "  -measureonly          Only output measurements, no predictor is built.\r\n",
      "  -f FORCEMODEL         Force model type: DT, NN, RF  Default: RF\r\n",
      "  -nosplit              Use all of the data for training. Default: dataset is split between training and validation.\r\n",
      "  -split FORCESPLIT     Pass it an integer between 50 and 90 telling our system to use that percent of the data for training, and the rest for validation\r\n",
      "\r\n",
      "\u001b[01;1mIntermediate options\u001b[0m:\r\n",
      "  -nsamples NSAMPLES    Train only on a subset of N random samples of the dataset. Default: entire dataset.\r\n",
      "  -ignoreclasses IGNORELABELS\r\n",
      "                        Comma-separated list of classes to ignore.\r\n",
      "  -usecolumns IMPORTANTCOLUMNS\r\n",
      "                        Comma-separated list of columns by name or number used to build the predictor.\r\n",
      "  -o OUTPUT             Predictor filename. Default: a.py\r\n",
      "  -v                    Verbose output\r\n",
      "  -q                    Quiet operation.\r\n",
      "  -y                    Answers yes to all overwrite questions.\r\n",
      "\r\n",
      "\u001b[01;1mAdvanced options\u001b[0m:\r\n",
      "  -e EFFORT             Increase compute time to improve accuracy. 1=<EFFORT<100. Default: 1\r\n",
      "  -biasmeter            Measure model bias\r\n",
      "  -novalidation         Do not measure validation scores for created predictor.\r\n",
      "  -nofun                Stop compilation if there are warnings.\r\n",
      "  -modelonly            Perform only the measurements needed to build the model.\r\n",
      "  -json JSON            Document the session using json formatting.\r\n",
      "\r\n",
      "  -C REGULARIZATION_STRENGTH\r\n",
      "\r\n",
      "\u001b[01;1mExamples:\r\n",
      "\u001b[0mMeasure and build a random forest predictor for titanic\r\n",
      "\u001b[01;34m\tbrainome https://download.brainome.ai/data/public/titanic_train.csv \r\n",
      "\r\n",
      "\u001b[0mBuild a better predictor by ignoring columns:\r\n",
      "\u001b[01;34m\tbrainome titanic_train.csv -ignorecolumns \"PassengerId,Name\" -target Survived \r\n",
      "\r\n",
      "\u001b[0mAutomatically select the important columns by using ranking:\r\n",
      "\u001b[01;34m\tbrainome titanic_train.csv -rank -target Survived \r\n",
      "\r\n",
      "\u001b[0mBuild a neural network model with effort of 5:\r\n",
      "\u001b[01;34m\tbrainome titanic_train.csv -f NN -e 5 -target Survived\r\n",
      "\r\n",
      "\u001b[0mMeasure headerless dataset:\r\n",
      "\u001b[01;34m\tbrainome https://download.brainome.ai/data/public/bank.csv -headerless -measureonly\r\n",
      "\r\n",
      "\u001b[0mFull documentation can be found at https://www.brainome.ai/documentation\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!brainome --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[01;1mBrainome Table Compiler v1.8-120-prod\u001b[0m\n",
      "Copyright (c) 2019-2022 Brainome, Inc. All Rights Reserved.\n",
      "Licensed to:                 Paul Ngo  (Evaluation)\n",
      "Expiration Date:             2022-07-31   100 days left\n",
      "Maximum File Size:           30 GB\n",
      "Maximum Instances:           unlimited\n",
      "Maximum Attributes:          unlimited\n",
      "Maximum Classes:             unlimited\n",
      "Connected to:                daimensions.brainome.ai  (local execution)\n",
      "\n",
      "\u001b[01;1mCommand:\u001b[0m\n",
      "    btc cifar10_train_data.csv --yes -o brainome_out.py -f NN\n",
      "\n",
      "Start Time:                 04/22/2022, 18:33 PDT\n",
      "\n",
      "Cleaning...done. \n",
      "Splitting into training and validation...done. \n",
      "Pre-training measurements...done. \n",
      "\n",
      "\n",
      "\u001b[01;1mPre-training Measurements\u001b[0m\n",
      "Data:\n",
      "    Input:                      cifar10_train_data.csv\n",
      "    Target Column:              Label\n",
      "    Number of instances:     100000\n",
      "    Number of attributes:         8 out of 8\n",
      "    Number of classes:            2\n",
      "\n",
      "Class Balance:                \n",
      "                               1: 50.00%\n",
      "                               0: 50.00%\n",
      "\n",
      "Learnability:\n",
      "    Best guess accuracy:          50.00%\n",
      "    Data Sufficiency:             Maybe enough data to generalize. [yellow]\n",
      "\n",
      "Capacity Progression:             at [ 5%, 10%, 20%, 40%, 80%, 100% ]\n",
      "    Ideal Machine Learner:             13,  14,  15,  15,  16,  16\n",
      "\n",
      "\n",
      "Expected Accuracy:              Training            Validation\n",
      "    Decision Tree:                99.31%                50.15%\n",
      "    Neural Network:                 ----                  ----\n",
      "    Random Forest:                99.68%                71.12%\n",
      "Recommendations:\n",
      "    Warning: Data has high information density. Using effort 5 and larger ( -e 5 ) can improve results.\n",
      "    If predictor accuracy is insufficient, try using the option -rank to automatically select the important attributes.\n",
      "    We recommend using Random Forest -f RF.\n",
      "    If predictor accuracy is insufficient, try using the effort option -e with a value of 5 or more to increase training time.\n",
      "    Model type NN given by user. \n",
      "\n",
      "\n",
      "Architecting model...done. \n",
      "Priming model...done. \n",
      "Compiling predictor...done. \n",
      "Validating predictor...done. \n",
      "\n",
      "\u001b[01;1mPredictor:\u001b[0m                        brainome_out.py\n",
      "    Classifier Type:              Neural Network\n",
      "    System Type:                  Binary classifier\n",
      "    Training / Validation Split:  60% : 40%\n",
      "    Accuracy:\n",
      "      Best-guess accuracy:        50.00%\n",
      "      Training accuracy:          85.63% (51380/60000 correct)\n",
      "      Validation Accuracy:        85.73% (34295/40000 correct)\n",
      "      Combined Model Accuracy:    85.67% (85675/100000 correct)\n",
      "\n",
      "\n",
      "    Model Capacity (MEC):         61    bits\n",
      "    Generalization Ratio:        842.29 bits/bit\n",
      "    Percent of Data Memorized:     0.24%\n",
      "    Resilience to Noise:          -2.93 dB\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Training Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "              ------ | ---------\n",
      "                   1 |  25488   4512 \n",
      "                   0 |   4108  25892 \n",
      "\n",
      "    Validation Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "              ------ | ---------\n",
      "                   1 |  16970   3030 \n",
      "                   0 |   2675  17325 \n",
      "\n",
      "    Training Accuracy by Class:\n",
      "               Label |     TP     FP     TN     FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "               ----- | ------ ------ ------ ------ -------- -------- -------- -------- -------- --------\n",
      "                   1 |  25488   4108  25892   4512   84.96%   86.31%   86.12%   85.16%   85.54%   74.73%\n",
      "                   0 |  25892   4512  25488   4108   86.31%   84.96%   85.16%   86.12%   85.73%   75.02%\n",
      "\n",
      "    Validation Accuracy by Class:\n",
      "               Label |     TP     FP     TN     FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "               ----- | ------ ------ ------ ------ -------- -------- -------- -------- -------- --------\n",
      "                   1 |  16970   2675  17325   3030   84.85%   86.62%   86.38%   85.11%   85.61%   74.84%\n",
      "                   0 |  17325   3030  16970   2675   86.62%   84.85%   85.11%   86.38%   85.86%   75.23%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "End Time:           04/22/2022, 18:35 PDT\n",
      "Runtime Duration:   2m 39s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!brainome cifar10_train_data.csv --yes -o brainome_out.py -f NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[01;1mBrainome Table Compiler v1.8-120-prod\u001b[0m\n",
      "Copyright (c) 2019-2022 Brainome, Inc. All Rights Reserved.\n",
      "Licensed to:                 Paul Ngo  (Evaluation)\n",
      "Expiration Date:             2022-07-31   100 days left\n",
      "Maximum File Size:           30 GB\n",
      "Maximum Instances:           unlimited\n",
      "Maximum Attributes:          unlimited\n",
      "Maximum Classes:             unlimited\n",
      "Connected to:                daimensions.brainome.ai  (local execution)\n",
      "\n",
      "\u001b[01;1mCommand:\u001b[0m\n",
      "    btc cifar10_train_data.csv --yes -o brainome_out.py -f NN -nosplit -v\n",
      "\n",
      "Start Time:                 04/22/2022, 19:52 PDT\n",
      "\n",
      "Cleaning...done. < 1s\n",
      "Splitting into training and validation...done. 1s\n",
      "Pre-training measurements...done. 1m 25s\n",
      "\n",
      "\n",
      "\u001b[01;1mPre-training Measurements\u001b[0m\n",
      "Data:\n",
      "    Input:                      cifar10_train_data.csv\n",
      "    Target Column:              Label\n",
      "    Number of instances:     100000\n",
      "    Number of attributes:         8 out of 8\n",
      "    Number of classes:            2\n",
      "\n",
      "Class Balance:                \n",
      "                               1: 50.00%\n",
      "                               0: 50.00%\n",
      "\n",
      "Learnability:\n",
      "    Best guess accuracy:          50.00%\n",
      "    Data Sufficiency:             Maybe enough data to generalize. [yellow]\n",
      "\n",
      "Capacity Progression:             at [ 5%, 10%, 20%, 40%, 80%, 100% ]\n",
      "    Ideal Machine Learner:             13,  14,  15,  15,  16,  16\n",
      "\n",
      "Estimated Memory Equivalent Capacity:\n",
      "    Decision Tree:             49167 bits\n",
      "    Neural Networks:             161 bits\n",
      "    Random Forest:             14283 bits\n",
      "Percent of data that would be memorized:\n",
      "    Decision Tree:                99.01%\n",
      "    Neural Networks:             100.00%\n",
      "    Random Forest:                57.41%\n",
      "Expected Generalization:\n",
      "    Decision Tree:                 2.02 bits/bit\n",
      "    Neural Network:              621.12 bits/bit\n",
      "    Random Forest:                 7.00 bits/bit\n",
      "\n",
      "Expected Accuracy:              Training            Validation\n",
      "    Decision Tree:                99.31%                50.15%\n",
      "    Neural Network:                 ----                  ----\n",
      "    Random Forest:                99.68%                71.12%\n",
      "Recommendations:\n",
      "    Warning: Data has high information density. Using effort 5 and larger ( -e 5 ) can improve results.\n",
      "    If predictor accuracy is insufficient, try using the option -rank to automatically select the important attributes.\n",
      "    We recommend using Random Forest -f RF.\n",
      "    If predictor accuracy is insufficient, try using the effort option -e with a value of 5 or more to increase training time.\n",
      "    Model type NN given by user. \n",
      "\n",
      "\n",
      "Architecting model...done. 30s\n",
      "Priming model...done. 50s\n",
      "Compiling predictor...done. < 1s\n",
      "Validating predictor...done. < 1s\n",
      "\n",
      "\u001b[01;1mPredictor:\u001b[0m                        brainome_out.py\n",
      "    Classifier Type:              Neural Network\n",
      "    System Type:                  Binary classifier\n",
      "    Training / Validation Split:    Unable to split dataset. The predictor was trained and evaluated on the same data.\n",
      "    Accuracy:\n",
      "      Best-guess accuracy:        50.00%\n",
      "\n",
      "\n",
      "      Combined Model Accuracy:    83.57% (83573/100000 correct)\n",
      "\n",
      "\n",
      "    Model Capacity (MEC):         71    bits\n",
      "    Generalization Ratio:       1177.08 bits/bit\n",
      "    Percent of Data Memorized:     0.17%\n",
      "    Resilience to Noise:          -3.07 dB\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    System Meter Runtime Duration:    < 1s\n",
      "    Combined Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "              ------ | ---------\n",
      "                   1 |  41235   8765 \n",
      "                   0 |   7662  42338 \n",
      "\n",
      "\n",
      "\n",
      "    Combined Accuracy by Class:\n",
      "               Label |     TP     FP     TN     FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "               ----- | ------ ------ ------ ------ -------- -------- -------- -------- -------- --------\n",
      "                   1 |  41235   7662  42338   8765   82.47%   84.68%   84.33%   82.85%   83.39%   71.51%\n",
      "                   0 |  42338   8765  41235   7662   84.68%   82.47%   82.85%   84.33%   83.75%   72.05%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "End Time:           04/22/2022, 19:54 PDT\n",
      "Runtime Duration:   2m 49s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!brainome cifar10_train_data.csv --yes -o brainome_out.py -f NN -nosplit -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 00:27:31.964577: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib\n",
      "2022-04-25 00:27:31.964595: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.Input(shape=(8,)))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"cifar10_train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_data.iloc[:,:8].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80211818, 0.92904288, 0.6948095 , ..., 1.16653097, 1.12921667,\n",
       "        0.85217667],\n",
       "       [0.80114973, 0.93188608, 0.694646  , ..., 1.18456411, 1.159953  ,\n",
       "        0.85917276],\n",
       "       [1.38109553, 1.39587212, 1.24606717, ..., 1.51248622, 1.37117326,\n",
       "        1.05875003],\n",
       "       ...,\n",
       "       [1.81546283, 1.65248346, 1.50130939, ..., 1.95464873, 1.56047535,\n",
       "        1.28820598],\n",
       "       [1.26218724, 1.27680779, 1.15425003, ..., 1.38154137, 1.34287763,\n",
       "        1.0250144 ],\n",
       "       [1.32958472, 1.2330929 , 1.10385454, ..., 1.42520332, 1.24578607,\n",
       "        1.02405775]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = raw_data.iloc[:,8].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.6890 - accuracy: 0.5350\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 3s 301us/step - loss: 0.6765 - accuracy: 0.5771\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 3s 304us/step - loss: 0.6566 - accuracy: 0.6168\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 3s 305us/step - loss: 0.6317 - accuracy: 0.6486\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 3s 301us/step - loss: 0.6025 - accuracy: 0.6821\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 3s 304us/step - loss: 0.5673 - accuracy: 0.7205\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 3s 299us/step - loss: 0.5276 - accuracy: 0.7628\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 3s 300us/step - loss: 0.4881 - accuracy: 0.8024\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 3s 257us/step - loss: 0.4540 - accuracy: 0.8308\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 3s 267us/step - loss: 0.4289 - accuracy: 0.8464\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 3s 267us/step - loss: 0.4101 - accuracy: 0.85560s - loss: 0.4103 - accuracy: 0.85 - ETA: 0s - loss: 0.4104 - accuracy: 0.85\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 3s 269us/step - loss: 0.3977 - accuracy: 0.8602\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 3s 269us/step - loss: 0.3882 - accuracy: 0.8627\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 3s 275us/step - loss: 0.3794 - accuracy: 0.8663\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 3s 263us/step - loss: 0.3742 - accuracy: 0.8675\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 3s 261us/step - loss: 0.3699 - accuracy: 0.8694\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 3s 254us/step - loss: 0.3673 - accuracy: 0.8705\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 3s 263us/step - loss: 0.3654 - accuracy: 0.8703\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 3s 256us/step - loss: 0.3618 - accuracy: 0.8726\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 3s 254us/step - loss: 0.3622 - accuracy: 0.8707\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 3s 257us/step - loss: 0.3599 - accuracy: 0.8727\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 3s 257us/step - loss: 0.3595 - accuracy: 0.8730\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 3s 261us/step - loss: 0.3594 - accuracy: 0.8731\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 3s 258us/step - loss: 0.3561 - accuracy: 0.8733\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 3s 257us/step - loss: 0.3549 - accuracy: 0.8753\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 3s 260us/step - loss: 0.3553 - accuracy: 0.8752\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 3s 258us/step - loss: 0.3558 - accuracy: 0.8737\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 3s 264us/step - loss: 0.3535 - accuracy: 0.8755\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 3s 268us/step - loss: 0.3535 - accuracy: 0.87600s -\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 3s 265us/step - loss: 0.3535 - accuracy: 0.8755\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 3s 268us/step - loss: 0.3548 - accuracy: 0.8753\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 3s 262us/step - loss: 0.3535 - accuracy: 0.8765\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 3s 261us/step - loss: 0.3525 - accuracy: 0.8770\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 3s 260us/step - loss: 0.3524 - accuracy: 0.8763\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 3s 263us/step - loss: 0.3537 - accuracy: 0.8758\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 3s 266us/step - loss: 0.3512 - accuracy: 0.8769\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 3s 263us/step - loss: 0.3515 - accuracy: 0.8775\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 3s 263us/step - loss: 0.3519 - accuracy: 0.8761\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 3s 259us/step - loss: 0.3496 - accuracy: 0.8782\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 3s 257us/step - loss: 0.3503 - accuracy: 0.8780\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 3s 266us/step - loss: 0.3508 - accuracy: 0.8774\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 3s 261us/step - loss: 0.3504 - accuracy: 0.8772\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 3s 258us/step - loss: 0.3506 - accuracy: 0.8764\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 3s 266us/step - loss: 0.3506 - accuracy: 0.8782\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 3s 253us/step - loss: 0.3502 - accuracy: 0.8780\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 3s 256us/step - loss: 0.3490 - accuracy: 0.8779\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 3s 257us/step - loss: 0.3518 - accuracy: 0.8766\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 3s 263us/step - loss: 0.3502 - accuracy: 0.8769\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 3s 277us/step - loss: 0.3491 - accuracy: 0.8780\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 3s 304us/step - loss: 0.3494 - accuracy: 0.8793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f75e002cac0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_h, b_h = model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_o, b_o = model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.3640354 , -0.10273784, -0.6751391 , -0.3581928 , -0.13853669,\n",
       "         0.85019916, -0.4746667 , -0.2997676 ,  0.7618899 ,  0.89988965,\n",
       "        -0.3690588 , -0.5100057 , -0.46425712,  0.09240746,  0.19627994,\n",
       "         0.7246859 ],\n",
       "       [-2.0665596 ,  1.3648514 ,  1.1946207 , -0.2906499 , -0.4653932 ,\n",
       "        -1.7017239 ,  0.25025582, -0.26208842, -1.1886315 , -1.7089199 ,\n",
       "         0.42861348, -0.51174307,  0.20051289, -0.0206387 ,  1.6312796 ,\n",
       "        -1.4796364 ],\n",
       "       [-0.22636682,  0.09247222, -0.43782812,  0.32508707, -0.4341849 ,\n",
       "         0.3516699 ,  0.21297944,  0.30395257, -0.21749139, -0.2517772 ,\n",
       "        -0.36406204,  0.20887908, -0.41264272, -0.35000634,  0.4220969 ,\n",
       "        -0.10533819],\n",
       "       [ 0.09742023,  0.36949804,  0.5124769 , -0.26852143,  0.0244813 ,\n",
       "        -0.1209502 ,  0.10416758, -0.28383029,  0.3219538 ,  0.29377377,\n",
       "        -0.3809956 , -0.00616221, -0.39392388, -0.46517754, -0.16641705,\n",
       "        -0.2446984 ],\n",
       "       [-0.04845894,  0.37403715,  0.3264733 ,  0.00499678, -0.40135694,\n",
       "        -0.5624486 , -0.11596668,  0.16533685, -0.87908226, -0.30065933,\n",
       "        -0.05338797,  0.07041129,  0.3673364 ,  0.1906805 ,  0.79983574,\n",
       "         0.06689353],\n",
       "       [ 0.5385943 , -0.2659503 ,  0.13680172,  0.23817968, -0.47547567,\n",
       "         0.16681199, -0.1592772 ,  0.19614005,  0.3497462 ,  0.5278972 ,\n",
       "         0.2906156 ,  0.39819884, -0.40083528,  0.26163828,  0.02092282,\n",
       "         0.50577056],\n",
       "       [ 0.8920227 , -1.5463086 , -1.432442  , -0.2555021 , -0.03252566,\n",
       "         1.6433346 , -0.17350781,  0.1686784 ,  1.7729576 ,  1.5570664 ,\n",
       "        -0.36766586, -0.5071797 , -0.2660638 , -0.14725924, -2.028478  ,\n",
       "         1.6324916 ],\n",
       "       [-0.86195993,  0.7942849 ,  1.4654104 , -0.44855547,  0.22124577,\n",
       "        -0.82474965,  0.15142417, -0.1284703 , -1.3993474 , -1.1357236 ,\n",
       "         0.2788931 ,  0.3549648 ,  0.13828254, -0.34186018,  1.0848266 ,\n",
       "        -1.3885865 ]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01367188,  0.1735035 ,  0.14396368,  0.        ,  0.        ,\n",
       "        0.28711557,  0.        ,  0.        , -0.09063929, -0.2810001 ,\n",
       "       -0.04962711, -0.03020805,  0.        ,  0.        ,  0.27157122,\n",
       "        0.01795548], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-3.5722569e+01],\n",
       "        [ 1.3087072e+00],\n",
       "        [ 1.5581534e+00],\n",
       "        [ 4.3456006e-01],\n",
       "        [ 4.2737460e-01],\n",
       "        [-4.7071443e+00],\n",
       "        [-3.5133514e-01],\n",
       "        [ 2.6661325e-01],\n",
       "        [-9.3276072e+00],\n",
       "        [-6.7452927e+00],\n",
       "        [-4.4879299e-01],\n",
       "        [ 1.1720100e-02],\n",
       "        [ 3.5361540e-01],\n",
       "        [-1.8780094e-01],\n",
       "        [ 2.3053513e+00],\n",
       "        [-3.3297791e+01]], dtype=float32),\n",
       " array([0.36210632], dtype=float32))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_o, b_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
